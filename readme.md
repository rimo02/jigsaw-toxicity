# Toxic Comment Classification using DistilBERT

## Overview

This project aims to build a multi-headed model for detecting various types of toxicity in online comments, including:

- Toxic
- Severe Toxic
- Obscene
- Threat
- Insult
- Identity Hate

Utilizing the DistilBERT model, this approach fine-tunes the model on a dataset of comments from Wikipedia's talk page edits. The model is then deployed using FastAPI, allowing for easy interaction and testing of its capabilities.

# Sample
![image](https://github.com/user-attachments/assets/cf0a3539-dc01-4816-9a0c-6d62e671ea21)


---
### Note
Run the Jupyter notebook to train the model or contact me to get the pretrained model weights
